{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Integração do modelo do Bedrock com os agentes do LangChain\n",
    "\n",
    "Algumas aplicações exigem uma sequência adaptável de chamadas para modelos de linguagem e diversos recursos dependendo de entrada do usuário. A interface do agente possibilita ter a flexibilidade necessária para essas aplicações. Um agente tem disponibilidade para uma gama de recursos e seleciona quais utilizar com base nas entradas do usuário. Os agentes conseguem utilizar várias ferramentas e usar o resultado de uma ferramenta como entrada para a outra.  \n",
    "\n",
    "Existem duas categorias principais de agentes:\n",
    "\n",
    "- Agentes de ação: em cada intervalo, eles determinam a ação subsequente usando os resultados de todas as ações anteriores. \n",
    "- Agentes plan-and-execute: determinam a ordem completa das ações inicialmente, depois implementam todas sem atualizar o plano.\n",
    "\n",
    "Neste caderno, demonstraremos o uso de agentes `plan-and-execute` juntamente com o `Zero-shot ReAct`, um agente de ação que usa o framework [`ReAct`](https://arxiv.org/pdf/2205.00445.pdf) para selecionar a ferramenta apropriada com base exclusivamente na descrição da ferramenta. Para isso, você precisa fornecer a descrição de cada ferramenta. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Arquitetura\n",
    "![](./images/arch-agents.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import sys\n",
    "import boto3\n",
    "\n",
    "# ---- ⚠️ Un-comment and edit the below lines as needed for your AWS setup ⚠️ ----\n",
    "\n",
    "# os.environ[\"AWS_DEFAULT_REGION\"] = \"<REGION_NAME>\"  # E.g. \"us-east-1\"\n",
    "# os.environ[\"AWS_PROFILE\"] = \"<YOUR_PROFILE>\"\n",
    "# os.environ[\"BEDROCK_ASSUME_ROLE\"] = \"<YOUR_ROLE_ARN>\"  # E.g. \"arn:aws:...\"\n",
    "os.environ['SERPAPI_API_KEY'] = \"<YOUR_SERP_API_KEY>\" # Required for the search tool\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_parameter = {\"temperature\": 0.0, \"top_p\": .5, \"max_tokens_to_sample\": 2000}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Como usar o ReAct: sinergia de raciocínio e atuação no framework de modelos de linguagem\n",
    "Modelos grandes de linguagem podem gerar explicações para seus raciocínios e respostas específicas para tarefas alternadamente. \n",
    "\n",
    "A produção de explicações de raciocínio permite que o modelo suponha, monitore e revise planos de ação e até mesmo lide com cenários inesperados. A etapa de ação permite que o modelo faça a interface e obtenha informações de fontes externas, como ambientes ou bases de conhecimento.\n",
    "\n",
    "O framework ReAct pode permitir que modelos grandes de linguagem interajam com ferramentas externas para obter informações que resultem em respostas mais precisas e baseadas em fatos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.agents import load_tools\n",
    "from langchain.agents import initialize_agent, Tool\n",
    "from langchain.agents import AgentType\n",
    "from langchain.llms.bedrock import Bedrock\n",
    "from langchain import LLMMathChain\n",
    "from langchain.utilities import SerpAPIWrapper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Carregue dois objetos de LLM únicos com parâmetros de modelo únicos, um para o agente e outro para a cadeia matemática.\n",
    "\n",
    "Um LLM único com sequências de interrupção para cadeias matemáticas ajuda a evitar que o Claude seja excessivamente detalhado ao executar a cadeia matemática.\n",
    "\n",
    "Além disso, adaptaremos o modelo padrão para funcionar melhor com o Claude, já que os modelos padrão do LangChain não se encaixam tão bem por padrão, então incluiremos a ferramenta recém-criada à nossa lista de ferramentas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "react_agent_llm = Bedrock(model_id=\"anthropic.claude-instant-v1\", model_kwargs=model_parameter)\n",
    "math_chain_llm = Bedrock(model_id=\"anthropic.claude-instant-v1\",\n",
    "                         model_kwargs={\"temperature\":0,\"stop_sequences\" : [\"```output\"]})\n",
    "\n",
    "tools = load_tools([\"serpapi\"], llm=react_agent_llm)\n",
    "\n",
    "llm_math_chain = LLMMathChain(llm=math_chain_llm, verbose=True)\n",
    "\n",
    "llm_math_chain.llm_chain.prompt.template = \"\"\"Human: Given a question with a math problem, provide only a single line mathematical expression that solves the problem in the following format. Don't solve the expression only create a parsable expression.\n",
    "```text\n",
    "${{single line mathematical expression that solves the problem}}\n",
    "```\n",
    "\n",
    "Assistant:\n",
    " Here is an example response with a single line mathematical expression for solving a math problem:\n",
    "```text\n",
    "37593**(1/5)\n",
    "```\n",
    "\n",
    "Human: {question}\n",
    "\n",
    "Assistant:\"\"\"\n",
    "\n",
    "tools.append(\n",
    "    Tool.from_function(\n",
    "        func=llm_math_chain.run,\n",
    "        name=\"Calculator\",\n",
    "        description=\"Useful for when you need to answer questions about math.\",\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "react_agent = initialize_agent(tools, \n",
    "                               react_agent_llm, \n",
    "                               agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION, \n",
    "                               verbose=True,\n",
    "                            #    max_iteration=2,\n",
    "                            #    return_intermediate_steps=True,\n",
    "                            #    handle_parsing_errors=True,\n",
    "                               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = \"\"\"Use the following format:\n",
    "Question: the input question you must answer\n",
    "Thought: you should always think about what to do, Also try to follow steps mentioned above\n",
    "Action: the action to take, should be one of [\"Search\", \"Calculator\"]\n",
    "Action Input: the input to the action\n",
    "Observation: the result of the action\n",
    "... (this Thought/Action/Action Input/Observation can repeat N times)\n",
    "Thought: I now know the final answer\n",
    "Final Answer: the final answer to the original input question\n",
    "\n",
    "Question: {input}\n",
    "\n",
    "Assistant:\n",
    "{agent_scratchpad}\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "react_agent.agent.llm_chain.prompt.template=prompt_template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"What is Amazon SageMaker? What is the launch year multiplied by 2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "react_agent(question)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Geração do código da ferramenta\n",
    "É possível usar GenAI para criar o código nas ferramentas? Claro! Com cuidado, pois há variações no código e \n",
    "pode não ser seguro para a execução sem análise humana.\n",
    "\n",
    "O exemplo a seguir usa o código gerado pelo Claude para gerar a ferramenta. Substitui a ferramenta EC2Search acima pelo código boto python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "from IPython.display import display, Markdown, Latex\n",
    "\n",
    "boto3_bedrock = boto3.client(service_name='bedrock-runtime',\n",
    "                             region_name=os.environ[\"AWS_DEFAULT_REGION\"])\n",
    "\n",
    "prompt_data = \"\"\"\n",
    "Human: You are an AI python code generator. You write really great code.\n",
    "\n",
    "Write a python function named list_tagged_instances with one parameter named tagname. \n",
    "\n",
    "The function queries the boto3 library to return a list all of the EC2 instances that have a tag equal to the tagname parameter. \n",
    "\n",
    "return the code inside <code></code>.\n",
    "Assistant:\"\"\"\n",
    "\n",
    "body = json.dumps({\"prompt\": prompt_data, \"max_tokens_to_sample\": 500})\n",
    "modelId = \"anthropic.claude-instant-v1\"  \n",
    "accept = \"application/json\"\n",
    "contentType = \"application/json\"\n",
    "\n",
    "response = boto3_bedrock.invoke_model(\n",
    "    body=body, modelId=modelId, accept=accept, contentType=contentType\n",
    ")\n",
    "response_body = json.loads(response.get(\"body\").read())\n",
    "\n",
    "tree = ET.ElementTree(ET.fromstring(response_body.get(\"completion\")))\n",
    "python_code = tree.getroot().text\n",
    "\n",
    "display(Markdown(f'```{python_code}```'))\n",
    "\n",
    "exec(python_code)\n",
    "\n",
    "tools = [\n",
    "    Tool.from_function(\n",
    "        func=list_tagged_instances,\n",
    "        name=\"List\",\n",
    "        description=\"Queries the boto3 library to return a list all of the EC2 instances that have a tag equal to the tagname parameter.\"\n",
    "    ),\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Execução do código\n",
    "Se o código acima parecer razoável, podemos usá-lo para executar nosso agente.\n",
    "\n",
    "**Observação: para este trabalho, você precisa de uma instância do EC2 nesta conta com uma tag chamada “delete” e algum valor na tag. Ela diferencia maiúsculas e minúsculas, então, antes de executar o trabalho, crie uma instância do EC2 e a defina para o estado interrompido."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "llm = Bedrock(model_id=\"anthropic.claude-instant-v1\", client=boto3_bedrock, model_kwargs=model_parameter)\n",
    "\n",
    "react_agent = initialize_agent(tools, llm, agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION, verbose=True)\n",
    "\n",
    "question = \"\"\"Human: Please list my EC2 instances with the tag delete.\n",
    "Assistant:\"\"\"\n",
    "\n",
    "result = react_agent.run(question)\n",
    "\n",
    "print(f\"{result}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outra variação — Pesquisar por uma instância que não existe\n",
    "O prompt muda para pesquisar por instâncias do EC2 com uma tag que não existe, então nenhuma instância deve aparecer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "question = \"\"\"Human: Please list my EC2 instances with the tag doesnotexist.\n",
    "Assistant:\"\"\"\n",
    "\n",
    "result = react_agent(question)\n",
    "\n",
    "print(f\"{result}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ferramentas de banco de dados\n",
    "Um uso comum para o agente é pesquisar um registro em um banco de dados. Não seria prático incluir todo o banco de dados no contexto, então você pode fornecer ferramentas que realizam ações com base no banco de dados e eliminam alucinações, ao mesmo tempo em que mantêm as interações conversacionais.\n",
    "\n",
    "### Agente do banco de dados SQL\n",
    "O LangChain tem um agente de banco de dados SQL para demonstração de como fazer perguntas a uma DB para obter respostas. Para saber mais detalhes, leia este documento: https://python.langchain.com/docs/integrations/toolkits/sql_database\n",
    "\n",
    "O agente carregará o esquema do DB no contexto e gerará declarações do SQL com base em perguntas de linguagem natural. Em seguida, a declaração do SQL é executada com referência ao banco de dados e o resultado é enviado.\n",
    "\n",
    "### Agentes de dados\n",
    "Enquanto o agente de banco de dados SQL é útil para exploração de dados e geração de consultas, também há casos em que você gostaria de \n",
    "Para entidades específicas, pode ser criada uma ferramenta para recuperar dados do banco de dados e fornecer próximas etapas de contexto no prompt.\n",
    "\n",
    "O exemplo a seguir simulará uma consulta de DB para um cliente na tabela de clientes. Substitua esse código por um DynamoDB ib de pesquisa ou um banco de dados de relação."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_table=[\n",
    "  {\n",
    "    \"id\": 1, \n",
    "    \"first_name\": \"John\", \n",
    "    \"last_name\": \"Doe\",\n",
    "    \"age\": 35,\n",
    "    \"postal_code\": \"90210\"\n",
    "  },\n",
    "  {  \n",
    "    \"id\": 2,\n",
    "    \"first_name\": \"Jane\",\n",
    "    \"last_name\": \"Smith\", \n",
    "    \"age\": 27,\n",
    "    \"postal_code\": \"12345\"\n",
    "  },\n",
    "  {\n",
    "    \"id\": 3, \n",
    "    \"first_name\": \"Bob\",\n",
    "    \"last_name\": \"Jones\",\n",
    "    \"age\": 42,\n",
    "    \"postal_code\": \"55555\"\n",
    "  },\n",
    "  {\n",
    "    \"id\": 4,\n",
    "    \"first_name\": \"Sara\", \n",
    "    \"last_name\": \"Miller\",\n",
    "    \"age\": 29, \n",
    "    \"postal_code\": \"13579\"\n",
    "  },\n",
    "  {\n",
    "    \"id\": 5,\n",
    "    \"first_name\": \"Mark\",\n",
    "    \"last_name\": \"Davis\",\n",
    "    \"age\": 31,\n",
    "    \"postal_code\": \"02468\"\n",
    "  },\n",
    "  {\n",
    "    \"id\": 6,\n",
    "    \"first_name\": \"Laura\",\n",
    "    \"last_name\": \"Wilson\",\n",
    "    \"age\": 24,\n",
    "    \"postal_code\": \"98765\" \n",
    "  },\n",
    "  {\n",
    "    \"id\": 7,\n",
    "    \"first_name\": \"Steve\",\n",
    "    \"last_name\": \"Moore\",\n",
    "    \"age\": 36,\n",
    "    \"postal_code\": \"11223\"\n",
    "  },\n",
    "  {\n",
    "    \"id\": 8,\n",
    "    \"first_name\": \"Michelle\",\n",
    "    \"last_name\": \"Chen\",\n",
    "    \"age\": 22,\n",
    "    \"orders\": [\n",
    "        {\n",
    "            \"order_id\": 1,\n",
    "            \"description\": \"An order of 1 dozen pencils\"\n",
    "        },\n",
    "        {\n",
    "            \"order_id\": 2,\n",
    "            \"description\": \"An order of 2 markers\"\n",
    "        }\n",
    "    ],\n",
    "    \"postal_code\": \"33215\"\n",
    "  },\n",
    "  {\n",
    "    \"id\": 9,\n",
    "    \"first_name\": \"David\",\n",
    "    \"last_name\": \"Lee\",\n",
    "    \"age\": 29,\n",
    "    \"postal_code\": \"99567\"\n",
    "  },\n",
    "  {\n",
    "    \"id\": 10,\n",
    "    \"first_name\": \"Jessica\",\n",
    "    \"last_name\": \"Brown\",\n",
    "    \"age\": 18, \n",
    "    \"postal_code\": \"43210\"\n",
    "  }\n",
    "]\n",
    "\n",
    "def customer_lookup(id):\n",
    "    print(f\"search by customer {id}\")\n",
    "    for customer in customer_table:\n",
    "        if customer[\"id\"] == int(id):\n",
    "            print(f\"found customer {id} {customer}\")\n",
    "            return customer\n",
    "        \n",
    "    return None\n",
    "\n",
    "tools.append(Tool.from_function(\n",
    "        name=\"CustomerLookup\",\n",
    "        func=customer_lookup,  # Mock Function, replace with an api call\n",
    "        description=\"Use this when you need to lookup a customer by id.\"\n",
    "    ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "react_agent = initialize_agent(tools, llm, agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION, verbose=True)\n",
    "\n",
    "question = \"\"\"\\n\\nHuman: write one sentence summary about the information you know about the customer with an id of 2.\n",
    "\n",
    "\\n\\nAssistant: Here is the one sentence summary: \"\"\"\n",
    "\n",
    "result = react_agent.run(question)\n",
    "\n",
    "print(f\"{result}\")"
   ]
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   }
  ],
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science 3.0)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-west-2:236514542706:image/sagemaker-data-science-310-v1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "00878cbed564b904a98b4a19808853cb6b9988746b881ea025a8408713879bf5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}