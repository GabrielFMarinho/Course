{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dc40c48b-0c95-4757-a067-563cfccd51a5",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Invocar o modelo do Bedrock para geração de texto com o prompt Zero-shot\n",
    "\n",
    "> *Este caderno deve funcionar bem com o kernel **`Data Science 3.0`** no SageMaker Studio*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9a413e2-3c34-4073-9000-d8556537bb6a",
   "metadata": {},
   "source": [
    "## Introdução\n",
    "\n",
    "Neste caderno, mostramos a você como usar um LLM para gerar uma resposta de e-mail a um cliente que forneceu feedback negativo sobre a qualidade do atendimento ao cliente que recebeu do engenheiro de suporte. \n",
    "\n",
    "Usaremos o modelo grande do Amazon Titan Text do Bedrock com a API do Boto3. \n",
    "\n",
    "O prompt usado neste exemplo é chamado de prompt zero-shot porque não fornecemos nenhum exemplo de texto junto com sua classificação além do prompt.\n",
    "\n",
    "**Observação:** *este caderno pode ser executado dentro ou fora do ambiente AWS.*\n",
    "\n",
    "#### Contexto\n",
    "Para demonstrar a capacidade de geração de texto do Amazon Bedrock, exploraremos o uso do cliente Boto3 para se comunicar com a API do Amazon Bedrock. Demonstraremos as diferentes configurações disponíveis e como um comando simples pode gerar os resultados desejados.\n",
    "\n",
    "#### Padrão\n",
    "Simplesmente ofereceremos à API do Amazon Bedrock um comando que consiste em uma tarefa, uma instrução e um comando para que o modelo interno gere um resultado sem fornecer exemplos adicionais. Nosso objetivo é demonstrar como poderosos LLMs entendem facilmente a tarefa dada e geram resultados interessantes.\n",
    "\n",
    "![](./images/bedrock.jpg)\n",
    "\n",
    "#### Caso de uso\n",
    "Para demonstrar a capacidade de geração de modelos no Amazon Bedrock, vamos analisar o caso de uso de geração de um e-mail.\n",
    "\n",
    "#### Persona\n",
    "Você é Bob, um gerente de atendimento ao cliente na AnyCompany e alguns de seus clientes não estão satisfeitos com o atendimento ao cliente e estão fornecendo feedbacks negativos sobre o serviço prestado pelos engenheiros de atendimento ao cliente. Você gostaria de pedir suas sinceras desculpas a esses clientes pelo serviço ruim e recuperar a confiança deles. Você precisa da ajuda de um LLM para gerar um lote de e-mails amigáveis e personalizados ao sentimento do cliente da correspondência de e-mail anterior.\n",
    "\n",
    "#### Implementação\n",
    "Para atender este caso de uso, mostraremos neste caderno como gerar um e-mail de agradecimento com base no e-mail anterior do cliente. Usaremos o grande modelo Amazon Titan Text com a API do Amazon Bedrock com o cliente Boto3. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "776fd083",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import boto3\n",
    "import botocore\n",
    "\n",
    "module_path = \"..\"\n",
    "sys.path.append(os.path.abspath(module_path))\n",
    "from labutils import bedrock, print_ww\n",
    "\n",
    "# ---- ⚠️ Un-comment and edit the below lines as needed for your AWS setup ⚠️ ----\n",
    "\n",
    "# os.environ[\"AWS_DEFAULT_REGION\"] = \"<REGION_NAME>\"  # E.g. \"us-east-1\"\n",
    "# os.environ[\"AWS_PROFILE\"] = \"<YOUR_PROFILE>\"\n",
    "# os.environ[\"BEDROCK_ASSUME_ROLE\"] = \"<YOUR_ROLE_ARN>\"  # E.g. \"arn:aws:...\"\n",
    "\n",
    "\n",
    "boto3_bedrock = bedrock.get_bedrock_client(\n",
    "    assumed_role=os.environ.get(\"BEDROCK_ASSUME_ROLE\", None),\n",
    "    region=os.environ.get(\"AWS_DEFAULT_REGION\", None)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f634211-3de1-4390-8c3f-367af5554c39",
   "metadata": {},
   "source": [
    "## Geração de texto\n",
    "\n",
    "Seguindo o caso de uso explicado acima, vamos preparar um comando para o serviço Amazon Bedrock gerar um e-mail. Observe que este prompt precisaria ser modificado por [formatação Humano:/Assistente: para Claude.](https://docs.anthropic.com/claude/docs/human-and-assistant-formatting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45ee2bae-6415-4dba-af98-a19028305c98",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# create the prompt\n",
    "prompt_data = \"\"\"\n",
    "Command: Write an email from Bob, Customer Service Manager, to the customer \"John Doe\" \n",
    "who provided negative feedback on the service provided by our customer support \n",
    "engineer\"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc9784e5-5e9d-472d-8ef1-34108ee4968b",
   "metadata": {},
   "source": [
    "Vamos começar usando o grande modelo Amazon Titan. O Amazon Titan grande é compatível com uma janela de contexto de cerca de 4 mil tokens e aceita os seguintes parâmetros:\n",
    "- `inputText`: prompt para o LLM\n",
    "- `textGenerationConfig`: estes são os parâmetros que o modelo levará em consideração ao gerar o resultado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8af670eb-ad02-40df-a19c-3ed835fac8d9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "body = json.dumps({\n",
    "    \"inputText\": prompt_data, \n",
    "    \"textGenerationConfig\":{\n",
    "        \"maxTokenCount\":4096,\n",
    "        \"stopSequences\":[],\n",
    "        \"temperature\":0,\n",
    "        \"topP\":0.9\n",
    "        }\n",
    "    }) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4ca6751",
   "metadata": {},
   "source": [
    "A API do Amazon Bedrock fornece a você uma API `invoke_model` que aceita o seguinte:\n",
    "- `modelId`: este é o modelo de ARN de vários modelos de base disponíveis no Amazon Bedrock.\n",
    "- `accept`: o tipo de solicitação de comando.\n",
    "- `contentType`: o tipo de contexto do resultado.\n",
    "- `body`: uma string json string que consiste no prompt e nas configurações.\n",
    "\n",
    "Confira a [documentação](https://docs.aws.amazon.com/bedrock/latest/userguide/model-ids-arns.html) para obter os IDs do modelo de geração de texto disponíveis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "088cf6bf-dd73-4710-a0cc-6c11d220c431",
   "metadata": {},
   "source": [
    "#### Invocar o grande modelo de linguagem Amazon Titan"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "379498f2",
   "metadata": {},
   "source": [
    "Primeiro, veremos como o modelo gera um resultado com base no prompt criado anteriormente.\n",
    "\n",
    "##### Concluir a geração do resultado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecaceef1-0f7f-4ae5-8007-ff7c25335251",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "modelId = 'amazon.titan-tg1-large' # change this to use a different version from the model provider\n",
    "accept = 'application/json'\n",
    "contentType = 'application/json'\n",
    "outputText = \"\\n\"\n",
    "try:\n",
    "\n",
    "    response = boto3_bedrock.invoke_model(body=body, modelId=modelId, accept=accept, contentType=contentType)\n",
    "    response_body = json.loads(response.get('body').read())\n",
    "\n",
    "    outputText = response_body.get('results')[0].get('outputText')\n",
    "\n",
    "except botocore.exceptions.ClientError as error:\n",
    "    \n",
    "    if error.response['Error']['Code'] == 'AccessDeniedException':\n",
    "           print(f\"\\x1b[41m{error.response['Error']['Message']}\\\n",
    "                \\nTo troubeshoot this issue please refer to the following resources.\\\n",
    "                 \\nhttps://docs.aws.amazon.com/IAM/latest/UserGuide/troubleshoot_access-denied.html\\\n",
    "                 \\nhttps://docs.aws.amazon.com/bedrock/latest/userguide/security-iam.html\\x1b[0m\\n\")\n",
    "        \n",
    "    else:\n",
    "        raise error\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3748383a-c140-407f-a7f6-8f140ad57680",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# The relevant portion of the response begins after the first newline character\n",
    "# Below we print the response beginning after the first occurence of '\\n'.\n",
    "\n",
    "email = outputText[outputText.index('\\n')+1:]\n",
    "print_ww(email)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d69e1a0",
   "metadata": {},
   "source": [
    "##### Transmitir a geração do resultado\n",
    "Temos acima um e-mail de exemplo gerado pelo grande modelo Amazon Titan por meio da compreensão da solicitação de comando e uso de sua compreensão inerente das diferentes modalidades. Esta solicitação à API é síncrona e aguarda o modelo gerar todo o resultado.\n",
    "\n",
    "O Bedrock também é compatível com o resultado que pode ser transmitido conforme é gerado pelo modelo em blocos. Temos abaixo um exemplo de invocação do modelo com opção de transmissão. `invoke_model_with_response_stream` retorna um `ResponseStream` que pode ser lido."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad073290",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "output = []\n",
    "try:\n",
    "    \n",
    "    response = boto3_bedrock.invoke_model_with_response_stream(body=body, modelId=modelId, accept=accept, contentType=contentType)\n",
    "    stream = response.get('body')\n",
    "    \n",
    "    i = 1\n",
    "    if stream:\n",
    "        for event in stream:\n",
    "            chunk = event.get('chunk')\n",
    "            if chunk:\n",
    "                chunk_obj = json.loads(chunk.get('bytes').decode())\n",
    "                text = chunk_obj['outputText']\n",
    "                output.append(text)\n",
    "                print(f'\\t\\t\\x1b[31m**Chunk {i}**\\x1b[0m\\n{text}\\n')\n",
    "                i+=1\n",
    "            \n",
    "except botocore.exceptions.ClientError as error:\n",
    "    \n",
    "    if error.response['Error']['Code'] == 'AccessDeniedException':\n",
    "           print(f\"\\x1b[41m{error.response['Error']['Message']}\\\n",
    "                \\nTo troubeshoot this issue please refer to the following resources.\\\n",
    "                 \\nhttps://docs.aws.amazon.com/IAM/latest/UserGuide/troubleshoot_access-denied.html\\\n",
    "                 \\nhttps://docs.aws.amazon.com/bedrock/latest/userguide/security-iam.html\\x1b[0m\\n\")\n",
    "        \n",
    "    else:\n",
    "        raise error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a788be5",
   "metadata": {},
   "source": [
    "Isso ajuda a obter rapidamente o resultado do modelo e deixa o serviço concluí-lo enquanto você o lê. Isso ajuda em casos de uso em que há blocos de texto maiores que você solicita ao modelo que gere. Posteriormente, você pode combinar todos os blocos gerados para formar o resultado completo e usá-lo no seu caso de uso."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02d48c73",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print('\\t\\t\\x1b[31m**COMPLETE OUTPUT**\\x1b[0m\\n')\n",
    "complete_output = ''.join(output)\n",
    "print(complete_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64b08b3b",
   "metadata": {},
   "source": [
    "## Conclusão\n",
    "Você adquiriu experiência com o uso do SDK `boto3`, que oferece uma exposição básica à API do Amazon Bedrock. Pelo uso dessa API, você viu o caso de uso de geração de um e-mail de resposta ao feedback negativo de um cliente.\n",
    "\n",
    "### Conclusões\n",
    "- Adaptar este caderno para testar diferentes modelos disponíveis através do Amazon Bedrock, como modelos Antropich Claude e AI21 Labs Jurassic.\n",
    "- Alterar os prompts para seu caso de uso específico e avaliar o resultado de diferentes modelos.\n",
    "- Experimentar com o comprimento do token para entender a latência e a responsividade do serviço.\n",
    "- Aplicar diferentes princípios de engenharia de prompt para obter resultados melhores.\n",
    "\n",
    "## Agradecemos sua atenção"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cdf9261-1002-4da7-9124-943f72b43486",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   }
  ],
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science 3.0)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-west-2:236514542706:image/sagemaker-data-science-310-v1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}